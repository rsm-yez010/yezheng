{"title":"A Replication of Karlan and List (2007)","markdown":{"yaml":{"title":"A Replication of Karlan and List (2007)","author":"Ye Zheng","date":"today","callout-appearance":"minimal"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nThe experiment was conducted through a direct mail campaign by a liberal nonprofit organization in the United States. A total of 50,083 prior donors were randomly assigned to one of two main groups: a control group, which received a standard solicitation letter, and a treatment group, which received a matching grant offer.\n\nWithin the treatment group, participants were further randomized into subgroups with different matching ratios ($1:$1, $2:$1, or $3:$1), maximum matching amounts ($25,000, $50,000, $100,000, or unstated), and suggested donation levels (based on their previous giving history). Each donor received a four-page letter with content identical across groups, except for the inclusion or absence of matching grant language.\n\nThe goal of the experiment was to examine how changes in the price of giving (induced by the matching offers) affected the likelihood and amount of donations. The large sample size and real-world context made this a high-powered natural field experiment.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport pandas as pd\n\ndf = pd.read_stata(\"/Users/kris/Desktop/2025WORK/quarto_website/files/karlan_list_2007.dta\")\n```\n::::\n```{python}\ndf.shape\n\n```\nThe dataset contains 50,083 observations and 51 variables, each representing a past donor who received a fundraising letter as part of a randomized field experiment. The data were collected to study how matching grants influence charitable giving behavior.\n\n```{python}\ndf.describe()\n```\n```{python}\ndf['treatment'].value_counts() \n```\nSummary statistics suggest most variables are binary or categorical indicators. Several variables such as cases, nonlit, and couple contain some missing values, which should be considered during modeling. The average suggested donation ranges widely, with variables like ask1 and askd1 showing values between 0 and 1 (indicating binary splits or quantiles).\n\nOverall, the data are rich in both experimental variation and individual-level covariates, suitable for analyzing treatment effects through regression and stratified comparisons.\n\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nTo verify that the randomization was successful, I perform a balance test on several pre-treatment variables. Specifically, we compare the following variables across the treatment and control groups:\n- `mrm2`: months since last donation\n- `freq`: number of prior donations\n- `hpa`: highest previous contribution\n- `female`: gender indicator\n\nI conduct both **t-tests** and **OLS regressions** for each variable to assess statistical significance and confirm consistency across methods.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\nbalance_vars = ['mrm2', 'freq', 'hpa', 'female']\nttest_results = []\nreg_results = []\n\nfor var in balance_vars:\n    t0 = df[df['treatment'] == 0][var].dropna()\n    t1 = df[df['treatment'] == 1][var].dropna()\n    t_stat, p_val = ttest_ind(t1, t0, equal_var=False)\n    ttest_results.append((var, t_stat, p_val))\n\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    reg_results.append((var, model.params['treatment'], model.pvalues['treatment']))\n```\n::::\nAccording to the test result, none of the variables show statistically significant differences between treatment and control groups at the 5% level. The lowest p-value appears in the case of `female` (p ≈ 0.079), which is marginally significant under a 10% threshold, but still within an acceptable range for randomization.\n\nThese results confirm that the groups are generally well balanced across observed characteristics, supporting the internal validity of the experimental design. Importantly, our results align closely with those reported in **Table 1 of Karlan and List (2007)**, which also finds no significant imbalance on these and other pre-treatment covariates.\n```{python}\nttest_df = pd.DataFrame(ttest_results, columns=[\"Variable\", \"T-statistic\", \"P-value\"])\nreg_df = pd.DataFrame(reg_results, columns=[\"Variable\", \"Coeff (Regression)\", \"P-value\"])\nttest_df.merge(reg_df, on=\"Variable\")\n```\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\nTo examine whether matching grants increase the likelihood of donating, I compare the donation response rate between the treatment and control groups. The plot below shows the proportion of individuals who made a donation in each group.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n::::\n```{python}\nresponse_rate = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\nresponse_rate[\"Group\"] = response_rate[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\nax = sns.barplot(data=response_rate, x=\"Group\", y=\"gave\", palette=\"Set2\")\n\nfor i, val in enumerate(response_rate[\"gave\"]):\n    ax.text(i, val + 0.0015, f\"{val:.2%}\", ha='center', va='bottom', fontsize=12)\n\nplt.title(\"Donation Response Rate by Group\", fontsize=16)\nplt.xlabel(\"Group\", fontsize=14)\nplt.ylabel(\"Proportion Who Donated\", fontsize=14)\nplt.ylim(0, response_rate[\"gave\"].max() * 1.3)\nsns.despine()\nplt.tight_layout()\nplt.show()\n```\nThe figure above compares the donation response rate between the treatment and control groups. The treatment group, which received a matching grant offer, had a donation rate of **2.20%**, while the control group had a rate of **1.79%**.\n\nAlthough the absolute difference in response rates appears modest, it represents a relative increase of over **22%**, suggesting that the presence of a matching grant can meaningfully boost the likelihood of charitable giving. This provides early visual evidence supporting the hypothesis that price incentives (in the form of matching) increase donation behavior.\n\n---\nWe now formally test whether individuals in the treatment group were significantly more likely to donate than those in the control group.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\nt1 = df[df[\"treatment\"] == 1][\"gave\"]\nt0 = df[df[\"treatment\"] == 0][\"gave\"]\nt_stat, p_val = ttest_ind(t1, t0, equal_var=False)\n\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\ncoefs = model.params\npvals = model.pvalues\nconf_int = model.conf_int()\nresult_table = pd.DataFrame({\n    \"Coefficient\": coefs.round(4),\n    \"P-value\": pvals.round(4),\n    \"95% CI Lower\": conf_int[0].round(4),\n    \"95% CI Upper\": conf_int[1].round(4)\n})\n```\n::::\n```{python}\nresult_table\n```\nThe regression model estimates the effect of being in the treatment group on the probability of making a donation. According to the results, individuals who received the matching grant offer were **0.42 percentage points more likely to donate** compared to those in the control group. This effect is **statistically significant** (p = 0.0019), with a **95% confidence interval ranging from 0.15 to 0.68 percentage points**.\n\nAlthough the effect may appear small in absolute terms, it is meaningful given the low baseline response rate. This suggests that **simple behavioral nudges—such as informing donors that their contribution will be matched—can effectively increase participation in charitable giving**.\n\nThis result reinforces the visual difference we observed earlier and aligns with the findings reported in **Table 2a Panel A** of Karlan and List (2007), confirming the positive impact of matching grants on donor behavior.\n\n***\n\nTo complement the linear regression, we estimate a probit model for the binary outcome `gave`, with `treatment` as the only explanatory variable.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprobit_model.summary()\n\nparams = probit_model.params\npvals = probit_model.pvalues\nconf_int = probit_model.conf_int()\n```\n::::\n```{python}\nprobit_result = pd.DataFrame({\n    \"Coefficient\": params.round(4),\n    \"P-value\": pvals.round(4),\n    \"95% CI Lower\": conf_int[0].round(4),\n    \"95% CI Upper\": conf_int[1].round(4)\n})\nprobit_result\n```\nThis model confirms that people who were told their donation would be matched were more likely to give. Even though the number looks small, the effect is statistically real—not due to chance. In simple terms, **a matching grant makes people feel like their donation “counts more,” and that encourages them to act**.\n\nNote: While our linear regression result closely matches Table 3 Column 1 in Karlan and List (2007), our probit coefficient does not. This may be due to differences in specification, such as use of marginal effects or inclusion of additional covariates in the published model.\n\n***\n\n\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nTo examine whether higher match ratios increase donation likelihood, we perform a series of t-tests within the treatment group.\n\nWe tested whether different match ratios (1:1, 2:1, and 3:1) led to different donation rates using a series of t-tests within the treatment group. As shown in the table above, **none of the comparisons yielded statistically significant differences**, with all p-values well above the 0.05 threshold.\n\nThis suggests that **increasing the match size beyond 1:1 did not further motivate people to donate**, even though the higher ratios were framed as more generous. The results support the authors' conclusion on page 8 of Karlan and List (2007), which states that higher match ratios do not significantly improve donation response.\n\nIn fact, the p-value comparing 2:1 to 3:1 is 0.96, implying that those two offers performed nearly identically in terms of response rate. These findings reinforce the idea that **it is the presence of a match—not its magnitude—that drives behavior**.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nfrom scipy.stats import ttest_ind\n\ntreat = df[df[\"treatment\"] == 1]\n\nrate_1_1 = treat[treat[\"ratio\"] == 1][\"gave\"]\nrate_2_1 = treat[treat[\"ratio\"] == 2][\"gave\"]\nrate_3_1 = treat[treat[\"ratio\"] == 3][\"gave\"]\n\nt_1_2 = ttest_ind(rate_1_1, rate_2_1, equal_var=False)\nt_1_3 = ttest_ind(rate_1_1, rate_3_1, equal_var=False)\nt_2_3 = ttest_ind(rate_2_1, rate_3_1, equal_var=False)\n```\n::::\n```{python}\npd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"1:1 vs 3:1\", \"2:1 vs 3:1\"],\n    \"T-stat\": [t_1_2.statistic, t_1_3.statistic, t_2_3.statistic],\n    \"P-value\": [t_1_2.pvalue, t_1_3.pvalue, t_2_3.pvalue]\n}).round(4)\n```\n***\nTo complement the t-test analysis, we regress the donation outcome `gave` on the categorical variable `ratio` among treatment group members. The regression uses 1:1 as the reference group, and compares 2:1 and 3:1 match offers against it.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport statsmodels.formula.api as smf\ntreat[\"ratio1\"] = (treat[\"ratio\"] == 1).astype(int)\ntreat[\"ratio2\"] = (treat[\"ratio\"] == 2).astype(int)\ntreat[\"ratio3\"] = (treat[\"ratio\"] == 3).astype(int)\n\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=treat).fit()\n\n```\n::::\n```{python}\nmodel.summary2().tables[1].round(4)\n```\nAs shown in the table above, neither `ratio2` nor `ratio3` produces a statistically significant effect on donation response. Both coefficients are small (0.0019 and 0.0020) and have p-values greater than 0.3, indicating no meaningful difference relative to the 1:1 match.\n\nThese findings reinforce our earlier t-test results and strongly support the authors’ claim in Karlan and List (2007): **while the presence of a match increases donations, the size of the match (1:1 vs 2:1 vs 3:1) does not matter.**\n\nFrom the regression coefficients, we estimate the average donation response rate for each match ratio as follows:\n\n- **1:1 match**: 2.07% (intercept)\n- **2:1 match**: 2.26% (0.0207 + 0.0019)\n- **3:1 match**: 2.27% (0.0207 + 0.0020)\n\nThe estimated difference between the 2:1 and 1:1 match ratios is just **0.19 percentage points**, and the difference between 3:1 and 2:1 is only **0.01 percentage points**. Neither difference is statistically significant (p > 0.3 in both cases).\n\nThese small, non-significant differences reinforce the finding that **increasing the match ratio does not meaningfully affect donor behavior**. The results suggest that donors are responsive to the idea of matching, but not particularly sensitive to how large the match offer is.\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution\n\nWe restrict the analysis to individuals who made a donation and regress the donation amount on the treatment indicator. This allows us to assess whether the matching grant affects **how much people give, conditional on giving**.\n\nThe regression result shows that donors in the treatment group gave, on average, **$1.67 less** than those in the control group. However, this difference is **not statistically significant** (p = 0.56).\n\nImportantly, the treatment coefficient **does not have a clear causal interpretation** in this context. This is because we are conditioning on post-treatment behavior (`gave == 1`), which is itself affected by the treatment. As a result, this analysis describes patterns among donors, but it does not estimate the total causal effect of treatment on donation amount.\n\n```{python}\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\ndonated = df[df[\"gave\"] == 1]\n\ntreat_amt = donated[donated[\"treatment\"] == 1][\"amount\"]\ncontrol_amt = donated[donated[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\nmodel = smf.ols(\"amount ~ treatment\", data=donated).fit()\nmodel.summary2().tables[1].round(4)\n```\n***\nThe following histograms display the distribution of donation amounts among individuals who donated, separately for the treatment and control groups. In both cases, donations are right-skewed, with most contributions under $100.\n\nThe red vertical line represents the average donation in each group. As shown, the treatment group donated slightly less on average ($43.87) than the control group ($45.54), but the difference is small and visually negligible.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndonated = df[df[\"gave\"] == 1]\n\ntreat_amt = donated[donated[\"treatment\"] == 1][\"amount\"]\ncontrol_amt = donated[donated[\"treatment\"] == 0][\"amount\"]\n\navg_treat = treat_amt.mean()\navg_control = control_amt.mean()\n```\n::::\n```{python}\nplt.figure(figsize=(6, 4))\nsns.histplot(control_amt, bins=30, color='skyblue')\nplt.axvline(avg_control, color='red', linestyle='--')\nplt.title(\"Control Group: Donation Amount\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.text(avg_control + 2, plt.ylim()[1]*0.9,\n         f\"Mean: ${avg_control:.2f}\", color=\"red\", fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n```{python}\nplt.figure(figsize=(6, 4))\nsns.histplot(treat_amt, bins=30, color='lightgreen')\nplt.axvline(avg_treat, color='red', linestyle='--')\nplt.title(\"Treatment Group: Donation Amount\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.text(avg_treat + 2, plt.ylim()[1]*0.9,\n         f\"Mean: ${avg_treat:.2f}\", color=\"red\", fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n\nThese plots visually reinforce the regression result: **matching grants encourage more people to donate, but do not affect how much they give** once they’ve decided to donate.\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\nThe plot following demonstrates the Law of Large Numbers using a simulated donation experiment. We assume that donation rates are 1.8% in the control group and 2.2% in the treatment group. By simulating 10,000 draws from each group, we compute and plot the cumulative average of the differences in donation outcomes.\n\nAs shown, the cumulative difference is highly volatile at the beginning, fluctuating wildly due to small sample sizes. However, as more observations are included, the average **stabilizes and converges toward the true treatment effect of 0.004**, marked by the red dashed line.\n\nThis illustrates a fundamental principle in statistics: with larger sample sizes, the sample average tends to the true population mean. It also explains why we can rely on the t-test in large experiments—because the randomness “averages out.”\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nn = 10000\ncontrol = np.random.binomial(1, 0.018, n)\ntreatment = np.random.binomial(1, 0.022, n)\n\ndiff = treatment - control\n\ncumulative_avg = np.cumsum(diff) / np.arange(1, n+1)\n\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative Average (treatment - control)\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nplt.title(\"Simulation: Law of Large Numbers in Action\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Average Difference in Donation Rate\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n\n\n### Central Limit Theorem\n\nThese four histograms illustrate the Central Limit Theorem using simulated experiments at different sample sizes. For each sample size (50, 200, 500, and 1000), we simulate 1000 experiments by drawing from two Bernoulli distributions (with probabilities 0.018 and 0.022), compute the difference in means, and plot the distribution of these differences.\n\nAs seen in the plots:\n\n- With **small samples (n = 50)**, the distribution is noisy and non-normal.\n- As the **sample size increases**, the distribution becomes smoother, more symmetric, and centered around the true treatment effect (0.004), marked by the red dashed line.\n- At **n = 1000**, the distribution closely resembles a normal curve, confirming the Central Limit Theorem in action.\n\nThis shows that even when the underlying data is binary, the average difference across repeated samples approaches a normal distribution as sample size grows. This is **why t-tests are valid** in large-sample experiments: the assumptions of approximate normality are satisfied.\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nnp.random.seed(42)\n\ndef simulate_differences(n, reps=1000):\n    diffs = []\n    for _ in range(reps):\n        t = np.random.binomial(1, 0.022, n).mean()\n        c = np.random.binomial(1, 0.018, n).mean()\n        diffs.append(t - c)\n    return np.array(diffs)\n\nsample_sizes = [50, 200, 500, 1000]\nfig, axes = plt.subplots(2, 2, figsize=(8, 6))\n\nfor i, n in enumerate(sample_sizes):\n    diffs = simulate_differences(n)\n    ax = axes[i//2, i%2]\n    sns.histplot(diffs, bins=30, kde=True, ax=ax, color=\"skyblue\")\n    ax.set_title(f\"Sample size = {n}\")\n    ax.axvline(0.004, color='red', linestyle='--', label=\"True Effect\")\n    ax.legend()\n    ax.set_xlabel(\"Estimated Treatment Effect\")\n    ax.set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Central Limit Theorem Simulation: Distribution of Estimated Treatment Effects\", fontsize=14)\nplt.tight_layout()\nplt.subplots_adjust(top=0.90)\nplt.show()\n```\n\n## Conclusion\n\nThis A/B experiment evaluates whether offering a charitable donation match influences giving behavior. Our analysis reveals several key findings:\n\n- **Offering a matching grant increases the likelihood of donating**. Individuals who received the matching offer were significantly more likely to contribute than those in the control group, with a response rate difference of approximately 0.42 percentage points.\n- However, **the size of the match (1:1 vs 2:1 vs 3:1) has no meaningful effect**. Neither donation rates nor average donation amounts significantly varied across different match ratios. This suggests that **the presence of a match matters more than its magnitude**.\n- Among those who did donate, **the treatment had no effect on the amount donated**. Matching grants seem to increase participation but not donation size.\n\nTogether, these results align with the findings of Karlan and List (2007), reinforcing the idea that **psychological cues—such as telling donors their gift will be matched—can nudge people into giving**, but once they’re engaged, their level of generosity is guided by other personal factors.\n\nThis study highlights how **behavioral interventions can have measurable effects** even when monetary incentives are small, and how careful A/B testing can quantify such effects in real-world settings.\n","srcMarkdownNoYaml":"\n\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nThe experiment was conducted through a direct mail campaign by a liberal nonprofit organization in the United States. A total of 50,083 prior donors were randomly assigned to one of two main groups: a control group, which received a standard solicitation letter, and a treatment group, which received a matching grant offer.\n\nWithin the treatment group, participants were further randomized into subgroups with different matching ratios ($1:$1, $2:$1, or $3:$1), maximum matching amounts ($25,000, $50,000, $100,000, or unstated), and suggested donation levels (based on their previous giving history). Each donor received a four-page letter with content identical across groups, except for the inclusion or absence of matching grant language.\n\nThe goal of the experiment was to examine how changes in the price of giving (induced by the matching offers) affected the likelihood and amount of donations. The large sample size and real-world context made this a high-powered natural field experiment.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport pandas as pd\n\ndf = pd.read_stata(\"/Users/kris/Desktop/2025WORK/quarto_website/files/karlan_list_2007.dta\")\n```\n::::\n```{python}\ndf.shape\n\n```\nThe dataset contains 50,083 observations and 51 variables, each representing a past donor who received a fundraising letter as part of a randomized field experiment. The data were collected to study how matching grants influence charitable giving behavior.\n\n```{python}\ndf.describe()\n```\n```{python}\ndf['treatment'].value_counts() \n```\nSummary statistics suggest most variables are binary or categorical indicators. Several variables such as cases, nonlit, and couple contain some missing values, which should be considered during modeling. The average suggested donation ranges widely, with variables like ask1 and askd1 showing values between 0 and 1 (indicating binary splits or quantiles).\n\nOverall, the data are rich in both experimental variation and individual-level covariates, suitable for analyzing treatment effects through regression and stratified comparisons.\n\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nTo verify that the randomization was successful, I perform a balance test on several pre-treatment variables. Specifically, we compare the following variables across the treatment and control groups:\n- `mrm2`: months since last donation\n- `freq`: number of prior donations\n- `hpa`: highest previous contribution\n- `female`: gender indicator\n\nI conduct both **t-tests** and **OLS regressions** for each variable to assess statistical significance and confirm consistency across methods.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\nbalance_vars = ['mrm2', 'freq', 'hpa', 'female']\nttest_results = []\nreg_results = []\n\nfor var in balance_vars:\n    t0 = df[df['treatment'] == 0][var].dropna()\n    t1 = df[df['treatment'] == 1][var].dropna()\n    t_stat, p_val = ttest_ind(t1, t0, equal_var=False)\n    ttest_results.append((var, t_stat, p_val))\n\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    reg_results.append((var, model.params['treatment'], model.pvalues['treatment']))\n```\n::::\nAccording to the test result, none of the variables show statistically significant differences between treatment and control groups at the 5% level. The lowest p-value appears in the case of `female` (p ≈ 0.079), which is marginally significant under a 10% threshold, but still within an acceptable range for randomization.\n\nThese results confirm that the groups are generally well balanced across observed characteristics, supporting the internal validity of the experimental design. Importantly, our results align closely with those reported in **Table 1 of Karlan and List (2007)**, which also finds no significant imbalance on these and other pre-treatment covariates.\n```{python}\nttest_df = pd.DataFrame(ttest_results, columns=[\"Variable\", \"T-statistic\", \"P-value\"])\nreg_df = pd.DataFrame(reg_results, columns=[\"Variable\", \"Coeff (Regression)\", \"P-value\"])\nttest_df.merge(reg_df, on=\"Variable\")\n```\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\nTo examine whether matching grants increase the likelihood of donating, I compare the donation response rate between the treatment and control groups. The plot below shows the proportion of individuals who made a donation in each group.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n::::\n```{python}\nresponse_rate = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\nresponse_rate[\"Group\"] = response_rate[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\nax = sns.barplot(data=response_rate, x=\"Group\", y=\"gave\", palette=\"Set2\")\n\nfor i, val in enumerate(response_rate[\"gave\"]):\n    ax.text(i, val + 0.0015, f\"{val:.2%}\", ha='center', va='bottom', fontsize=12)\n\nplt.title(\"Donation Response Rate by Group\", fontsize=16)\nplt.xlabel(\"Group\", fontsize=14)\nplt.ylabel(\"Proportion Who Donated\", fontsize=14)\nplt.ylim(0, response_rate[\"gave\"].max() * 1.3)\nsns.despine()\nplt.tight_layout()\nplt.show()\n```\nThe figure above compares the donation response rate between the treatment and control groups. The treatment group, which received a matching grant offer, had a donation rate of **2.20%**, while the control group had a rate of **1.79%**.\n\nAlthough the absolute difference in response rates appears modest, it represents a relative increase of over **22%**, suggesting that the presence of a matching grant can meaningfully boost the likelihood of charitable giving. This provides early visual evidence supporting the hypothesis that price incentives (in the form of matching) increase donation behavior.\n\n---\nWe now formally test whether individuals in the treatment group were significantly more likely to donate than those in the control group.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\nt1 = df[df[\"treatment\"] == 1][\"gave\"]\nt0 = df[df[\"treatment\"] == 0][\"gave\"]\nt_stat, p_val = ttest_ind(t1, t0, equal_var=False)\n\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\ncoefs = model.params\npvals = model.pvalues\nconf_int = model.conf_int()\nresult_table = pd.DataFrame({\n    \"Coefficient\": coefs.round(4),\n    \"P-value\": pvals.round(4),\n    \"95% CI Lower\": conf_int[0].round(4),\n    \"95% CI Upper\": conf_int[1].round(4)\n})\n```\n::::\n```{python}\nresult_table\n```\nThe regression model estimates the effect of being in the treatment group on the probability of making a donation. According to the results, individuals who received the matching grant offer were **0.42 percentage points more likely to donate** compared to those in the control group. This effect is **statistically significant** (p = 0.0019), with a **95% confidence interval ranging from 0.15 to 0.68 percentage points**.\n\nAlthough the effect may appear small in absolute terms, it is meaningful given the low baseline response rate. This suggests that **simple behavioral nudges—such as informing donors that their contribution will be matched—can effectively increase participation in charitable giving**.\n\nThis result reinforces the visual difference we observed earlier and aligns with the findings reported in **Table 2a Panel A** of Karlan and List (2007), confirming the positive impact of matching grants on donor behavior.\n\n***\n\nTo complement the linear regression, we estimate a probit model for the binary outcome `gave`, with `treatment` as the only explanatory variable.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprobit_model.summary()\n\nparams = probit_model.params\npvals = probit_model.pvalues\nconf_int = probit_model.conf_int()\n```\n::::\n```{python}\nprobit_result = pd.DataFrame({\n    \"Coefficient\": params.round(4),\n    \"P-value\": pvals.round(4),\n    \"95% CI Lower\": conf_int[0].round(4),\n    \"95% CI Upper\": conf_int[1].round(4)\n})\nprobit_result\n```\nThis model confirms that people who were told their donation would be matched were more likely to give. Even though the number looks small, the effect is statistically real—not due to chance. In simple terms, **a matching grant makes people feel like their donation “counts more,” and that encourages them to act**.\n\nNote: While our linear regression result closely matches Table 3 Column 1 in Karlan and List (2007), our probit coefficient does not. This may be due to differences in specification, such as use of marginal effects or inclusion of additional covariates in the published model.\n\n***\n\n\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nTo examine whether higher match ratios increase donation likelihood, we perform a series of t-tests within the treatment group.\n\nWe tested whether different match ratios (1:1, 2:1, and 3:1) led to different donation rates using a series of t-tests within the treatment group. As shown in the table above, **none of the comparisons yielded statistically significant differences**, with all p-values well above the 0.05 threshold.\n\nThis suggests that **increasing the match size beyond 1:1 did not further motivate people to donate**, even though the higher ratios were framed as more generous. The results support the authors' conclusion on page 8 of Karlan and List (2007), which states that higher match ratios do not significantly improve donation response.\n\nIn fact, the p-value comparing 2:1 to 3:1 is 0.96, implying that those two offers performed nearly identically in terms of response rate. These findings reinforce the idea that **it is the presence of a match—not its magnitude—that drives behavior**.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nfrom scipy.stats import ttest_ind\n\ntreat = df[df[\"treatment\"] == 1]\n\nrate_1_1 = treat[treat[\"ratio\"] == 1][\"gave\"]\nrate_2_1 = treat[treat[\"ratio\"] == 2][\"gave\"]\nrate_3_1 = treat[treat[\"ratio\"] == 3][\"gave\"]\n\nt_1_2 = ttest_ind(rate_1_1, rate_2_1, equal_var=False)\nt_1_3 = ttest_ind(rate_1_1, rate_3_1, equal_var=False)\nt_2_3 = ttest_ind(rate_2_1, rate_3_1, equal_var=False)\n```\n::::\n```{python}\npd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"1:1 vs 3:1\", \"2:1 vs 3:1\"],\n    \"T-stat\": [t_1_2.statistic, t_1_3.statistic, t_2_3.statistic],\n    \"P-value\": [t_1_2.pvalue, t_1_3.pvalue, t_2_3.pvalue]\n}).round(4)\n```\n***\nTo complement the t-test analysis, we regress the donation outcome `gave` on the categorical variable `ratio` among treatment group members. The regression uses 1:1 as the reference group, and compares 2:1 and 3:1 match offers against it.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport statsmodels.formula.api as smf\ntreat[\"ratio1\"] = (treat[\"ratio\"] == 1).astype(int)\ntreat[\"ratio2\"] = (treat[\"ratio\"] == 2).astype(int)\ntreat[\"ratio3\"] = (treat[\"ratio\"] == 3).astype(int)\n\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=treat).fit()\n\n```\n::::\n```{python}\nmodel.summary2().tables[1].round(4)\n```\nAs shown in the table above, neither `ratio2` nor `ratio3` produces a statistically significant effect on donation response. Both coefficients are small (0.0019 and 0.0020) and have p-values greater than 0.3, indicating no meaningful difference relative to the 1:1 match.\n\nThese findings reinforce our earlier t-test results and strongly support the authors’ claim in Karlan and List (2007): **while the presence of a match increases donations, the size of the match (1:1 vs 2:1 vs 3:1) does not matter.**\n\nFrom the regression coefficients, we estimate the average donation response rate for each match ratio as follows:\n\n- **1:1 match**: 2.07% (intercept)\n- **2:1 match**: 2.26% (0.0207 + 0.0019)\n- **3:1 match**: 2.27% (0.0207 + 0.0020)\n\nThe estimated difference between the 2:1 and 1:1 match ratios is just **0.19 percentage points**, and the difference between 3:1 and 2:1 is only **0.01 percentage points**. Neither difference is statistically significant (p > 0.3 in both cases).\n\nThese small, non-significant differences reinforce the finding that **increasing the match ratio does not meaningfully affect donor behavior**. The results suggest that donors are responsive to the idea of matching, but not particularly sensitive to how large the match offer is.\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution\n\nWe restrict the analysis to individuals who made a donation and regress the donation amount on the treatment indicator. This allows us to assess whether the matching grant affects **how much people give, conditional on giving**.\n\nThe regression result shows that donors in the treatment group gave, on average, **$1.67 less** than those in the control group. However, this difference is **not statistically significant** (p = 0.56).\n\nImportantly, the treatment coefficient **does not have a clear causal interpretation** in this context. This is because we are conditioning on post-treatment behavior (`gave == 1`), which is itself affected by the treatment. As a result, this analysis describes patterns among donors, but it does not estimate the total causal effect of treatment on donation amount.\n\n```{python}\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\ndonated = df[df[\"gave\"] == 1]\n\ntreat_amt = donated[donated[\"treatment\"] == 1][\"amount\"]\ncontrol_amt = donated[donated[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\nmodel = smf.ols(\"amount ~ treatment\", data=donated).fit()\nmodel.summary2().tables[1].round(4)\n```\n***\nThe following histograms display the distribution of donation amounts among individuals who donated, separately for the treatment and control groups. In both cases, donations are right-skewed, with most contributions under $100.\n\nThe red vertical line represents the average donation in each group. As shown, the treatment group donated slightly less on average ($43.87) than the control group ($45.54), but the difference is small and visually negligible.\n\n:::: {.callout-note collapse=\"true\"}\n### Coding\n```{python}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndonated = df[df[\"gave\"] == 1]\n\ntreat_amt = donated[donated[\"treatment\"] == 1][\"amount\"]\ncontrol_amt = donated[donated[\"treatment\"] == 0][\"amount\"]\n\navg_treat = treat_amt.mean()\navg_control = control_amt.mean()\n```\n::::\n```{python}\nplt.figure(figsize=(6, 4))\nsns.histplot(control_amt, bins=30, color='skyblue')\nplt.axvline(avg_control, color='red', linestyle='--')\nplt.title(\"Control Group: Donation Amount\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.text(avg_control + 2, plt.ylim()[1]*0.9,\n         f\"Mean: ${avg_control:.2f}\", color=\"red\", fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n```{python}\nplt.figure(figsize=(6, 4))\nsns.histplot(treat_amt, bins=30, color='lightgreen')\nplt.axvline(avg_treat, color='red', linestyle='--')\nplt.title(\"Treatment Group: Donation Amount\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.text(avg_treat + 2, plt.ylim()[1]*0.9,\n         f\"Mean: ${avg_treat:.2f}\", color=\"red\", fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n\nThese plots visually reinforce the regression result: **matching grants encourage more people to donate, but do not affect how much they give** once they’ve decided to donate.\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\nThe plot following demonstrates the Law of Large Numbers using a simulated donation experiment. We assume that donation rates are 1.8% in the control group and 2.2% in the treatment group. By simulating 10,000 draws from each group, we compute and plot the cumulative average of the differences in donation outcomes.\n\nAs shown, the cumulative difference is highly volatile at the beginning, fluctuating wildly due to small sample sizes. However, as more observations are included, the average **stabilizes and converges toward the true treatment effect of 0.004**, marked by the red dashed line.\n\nThis illustrates a fundamental principle in statistics: with larger sample sizes, the sample average tends to the true population mean. It also explains why we can rely on the t-test in large experiments—because the randomness “averages out.”\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nn = 10000\ncontrol = np.random.binomial(1, 0.018, n)\ntreatment = np.random.binomial(1, 0.022, n)\n\ndiff = treatment - control\n\ncumulative_avg = np.cumsum(diff) / np.arange(1, n+1)\n\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label=\"Cumulative Average (treatment - control)\")\nplt.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nplt.title(\"Simulation: Law of Large Numbers in Action\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Average Difference in Donation Rate\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n\n\n### Central Limit Theorem\n\nThese four histograms illustrate the Central Limit Theorem using simulated experiments at different sample sizes. For each sample size (50, 200, 500, and 1000), we simulate 1000 experiments by drawing from two Bernoulli distributions (with probabilities 0.018 and 0.022), compute the difference in means, and plot the distribution of these differences.\n\nAs seen in the plots:\n\n- With **small samples (n = 50)**, the distribution is noisy and non-normal.\n- As the **sample size increases**, the distribution becomes smoother, more symmetric, and centered around the true treatment effect (0.004), marked by the red dashed line.\n- At **n = 1000**, the distribution closely resembles a normal curve, confirming the Central Limit Theorem in action.\n\nThis shows that even when the underlying data is binary, the average difference across repeated samples approaches a normal distribution as sample size grows. This is **why t-tests are valid** in large-sample experiments: the assumptions of approximate normality are satisfied.\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nnp.random.seed(42)\n\ndef simulate_differences(n, reps=1000):\n    diffs = []\n    for _ in range(reps):\n        t = np.random.binomial(1, 0.022, n).mean()\n        c = np.random.binomial(1, 0.018, n).mean()\n        diffs.append(t - c)\n    return np.array(diffs)\n\nsample_sizes = [50, 200, 500, 1000]\nfig, axes = plt.subplots(2, 2, figsize=(8, 6))\n\nfor i, n in enumerate(sample_sizes):\n    diffs = simulate_differences(n)\n    ax = axes[i//2, i%2]\n    sns.histplot(diffs, bins=30, kde=True, ax=ax, color=\"skyblue\")\n    ax.set_title(f\"Sample size = {n}\")\n    ax.axvline(0.004, color='red', linestyle='--', label=\"True Effect\")\n    ax.legend()\n    ax.set_xlabel(\"Estimated Treatment Effect\")\n    ax.set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Central Limit Theorem Simulation: Distribution of Estimated Treatment Effects\", fontsize=14)\nplt.tight_layout()\nplt.subplots_adjust(top=0.90)\nplt.show()\n```\n\n## Conclusion\n\nThis A/B experiment evaluates whether offering a charitable donation match influences giving behavior. Our analysis reveals several key findings:\n\n- **Offering a matching grant increases the likelihood of donating**. Individuals who received the matching offer were significantly more likely to contribute than those in the control group, with a response rate difference of approximately 0.42 percentage points.\n- However, **the size of the match (1:1 vs 2:1 vs 3:1) has no meaningful effect**. Neither donation rates nor average donation amounts significantly varied across different match ratios. This suggests that **the presence of a match matters more than its magnitude**.\n- Among those who did donate, **the treatment had no effect on the amount donated**. Matching grants seem to increase participation but not donation size.\n\nTogether, these results align with the findings of Karlan and List (2007), reinforcing the idea that **psychological cues—such as telling donors their gift will be matched—can nudge people into giving**, but once they’re engaged, their level of generosity is guided by other personal factors.\n\nThis study highlights how **behavioral interventions can have measurable effects** even when monetary incentives are small, and how careful A/B testing can quantify such effects in real-world settings.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.27","theme":["cosmo","brand"],"title":"A Replication of Karlan and List (2007)","author":"Ye Zheng","date":"today","callout-appearance":"minimal"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}